{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Entropy Method\n",
    "\n",
    "## CartPole Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, obs_size: int, hidden_size: int, n_actions: int) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, n_actions),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import NumpyToTorch\n",
    "import torch.optim as optim\n",
    "\n",
    "from examples.cross_entropy import save_net_spec\n",
    "from velora.utils import load_config\n",
    "\n",
    "config = load_config(\"config/cp_ce.yaml\")\n",
    "env: gym.Env = NumpyToTorch(gym.make(\"CartPole-v1\"))\n",
    "\n",
    "obs_size = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "net = SimpleNet(obs_size, config.model.hidden_size, n_actions)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=net.parameters(), **config.optimizer)\n",
    "\n",
    "save_net_spec(net, \"saved/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: achronus (achronus-uk). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Projects\\portfolio\\velora\\examples\\wandb\\run-20241110_175717-9t3due4g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/achronus-uk/CrossEntropyTest/runs/9t3due4g' target=\"_blank\">CP-run-3</a></strong> to <a href='https://wandb.ai/achronus-uk/CrossEntropyTest' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/achronus-uk/CrossEntropyTest' target=\"_blank\">https://wandb.ai/achronus-uk/CrossEntropyTest</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/achronus-uk/CrossEntropyTest/runs/9t3due4g' target=\"_blank\">https://wandb.ai/achronus-uk/CrossEntropyTest/runs/9t3due4g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: loss=0.708, reward_mean=16.9, rw_bound=18.5\n",
      "1: loss=0.687, reward_mean=20.2, rw_bound=20.5\n",
      "2: loss=0.684, reward_mean=28.1, rw_bound=29.5\n",
      "3: loss=0.649, reward_mean=34.6, rw_bound=36.5\n",
      "4: loss=0.664, reward_mean=36.4, rw_bound=40.5\n",
      "5: loss=0.645, reward_mean=50.9, rw_bound=63.0\n",
      "6: loss=0.643, reward_mean=47.9, rw_bound=55.5\n",
      "7: loss=0.640, reward_mean=57.4, rw_bound=54.0\n",
      "8: loss=0.632, reward_mean=39.6, rw_bound=43.0\n",
      "9: loss=0.626, reward_mean=53.1, rw_bound=66.5\n",
      "10: loss=0.619, reward_mean=56.5, rw_bound=65.0\n",
      "11: loss=0.612, reward_mean=48.6, rw_bound=58.0\n",
      "12: loss=0.630, reward_mean=50.5, rw_bound=60.0\n",
      "13: loss=0.610, reward_mean=53.8, rw_bound=49.5\n",
      "14: loss=0.609, reward_mean=57.7, rw_bound=79.0\n",
      "15: loss=0.616, reward_mean=95.3, rw_bound=113.0\n",
      "16: loss=0.610, reward_mean=82.3, rw_bound=102.0\n",
      "17: loss=0.592, reward_mean=79.1, rw_bound=91.0\n",
      "18: loss=0.598, reward_mean=92.7, rw_bound=106.0\n",
      "19: loss=0.586, reward_mean=110.8, rw_bound=128.5\n",
      "20: loss=0.592, reward_mean=105.2, rw_bound=119.0\n",
      "21: loss=0.603, reward_mean=102.5, rw_bound=131.0\n",
      "22: loss=0.583, reward_mean=116.7, rw_bound=139.5\n",
      "23: loss=0.585, reward_mean=130.4, rw_bound=158.5\n",
      "24: loss=0.587, reward_mean=154.8, rw_bound=196.0\n",
      "25: loss=0.582, reward_mean=206.8, rw_bound=228.5\n",
      "Solved!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>ep_idx</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▇▇▅▆▅▄▄▄▃▃▃▄▃▃▃▃▂▂▁▂▂▁▁▁▁</td></tr><tr><td>reward_bound</td><td>▁▁▁▂▂▂▂▂▂▃▃▂▂▂▃▄▄▃▄▅▄▅▅▆▇█</td></tr><tr><td>reward_mean</td><td>▁▁▁▂▂▂▂▂▂▂▂▂▂▂▃▄▃▃▄▄▄▄▅▅▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>ep_idx</td><td>25</td></tr><tr><td>loss</td><td>0.5815</td></tr><tr><td>reward_bound</td><td>228.5</td></tr><tr><td>reward_mean</td><td>206.8125</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">CP-run-3</strong> at: <a href='https://wandb.ai/achronus-uk/CrossEntropyTest/runs/9t3due4g' target=\"_blank\">https://wandb.ai/achronus-uk/CrossEntropyTest/runs/9t3due4g</a><br/> View project at: <a href='https://wandb.ai/achronus-uk/CrossEntropyTest' target=\"_blank\">https://wandb.ai/achronus-uk/CrossEntropyTest</a><br/>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241110_175717-9t3due4g\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from examples.cross_entropy import train_cartpole\n",
    "\n",
    "train_cartpole(env, net, loss, optimizer, config, run_idx=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DiscreteObservationsToVector(gym.ObservationWrapper):\n",
    "    \"\"\"One hot encodes a discrete observation space.\"\"\"\n",
    "    def __init__(self, env: gym.Env) -> None:\n",
    "        super().__init__(env)\n",
    "\n",
    "        assert isinstance(env.observation_space, gym.spaces.Discrete)\n",
    "\n",
    "        shape = (env.observation_space.n,)\n",
    "        self.observation_space: gym.spaces.Box = gym.spaces.Box(0.0, 1.0, shape, dtype=np.float32)\n",
    "\n",
    "    def observation(self, observation: int) -> np.ndarray:\n",
    "        res = np.copy(self.observation_space.low)\n",
    "        res[observation] = 1.0\n",
    "        return res\n",
    "    \n",
    "    def step(self, action):\n",
    "        # Fixes bug with 'NumPyToTorch' wrapper\n",
    "        action = action.item() if isinstance(action, np.ndarray) else action\n",
    "        observation, reward, terminated, truncated, info = self.env.step(action)\n",
    "        return self.observation(observation), reward, terminated, truncated, info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FrozenLake Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 100\n",
    "GAMMA = 0.9\n",
    "\n",
    "env2: gym.Env = NumpyToTorch(DiscreteObservationsToVector(gym.make(\"FrozenLake-v1\", is_slippery=False)))\n",
    "\n",
    "obs_size = env2.observation_space.shape[0]\n",
    "n_actions = env2.action_space.n\n",
    "\n",
    "net2 = SimpleNet(obs_size, HIDDEN_SIZE, n_actions)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=net2.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_returns(batch: Episodes, gamma: float = 0.9) -> torch.FloatTensor:\n",
    "    \"\"\"\n",
    "    Returns a tensor of final discounted returns for each episode.\n",
    "    Calculated as: final_reward * (gamma ** (episode_length - 1))\n",
    "\n",
    "    Args:\n",
    "        gamma: Discount factor (default: 0.9)\n",
    "\n",
    "    Returns:\n",
    "        torch.FloatTensor: A tensor containing the final discounted return for each episode.\n",
    "    \"\"\"\n",
    "    returns = [ep.score() * (gamma ** len(ep)) for ep in batch]\n",
    "    return torch.tensor(returns, dtype=torch.float32)\n",
    "\n",
    "\n",
    "def filter_batch2(batch: Episodes, percentile: int) -> tuple[Episodes, torch.Tensor,torch.Tensor, float]:\n",
    "    ep_returns = final_returns(batch, GAMMA)\n",
    "    reward_bound = np.percentile(ep_returns.numpy(), percentile)\n",
    "    reward_mean = batch.scores().mean(dtype=torch.float32).item()\n",
    "\n",
    "    best_batches = Episodes()\n",
    "\n",
    "    for ep, disc_reward in zip(batch, ep_returns):\n",
    "        if disc_reward >= reward_bound and disc_reward != 0.:\n",
    "            best_batches.add(ep)\n",
    "\n",
    "    return best_batches, best_batches.observations(), best_batches.actions(), reward_bound, reward_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Projects\\portfolio\\velora\\examples\\wandb\\run-20241110_100627-8xq12tcz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/achronus-uk/CrossEntropyFrozenLake/runs/8xq12tcz' target=\"_blank\">gallant-capybara-1</a></strong> to <a href='https://wandb.ai/achronus-uk/CrossEntropyFrozenLake' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/achronus-uk/CrossEntropyFrozenLake' target=\"_blank\">https://wandb.ai/achronus-uk/CrossEntropyFrozenLake</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/achronus-uk/CrossEntropyFrozenLake/runs/8xq12tcz' target=\"_blank\">https://wandb.ai/achronus-uk/CrossEntropyFrozenLake/runs/8xq12tcz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: loss=1.384, reward_mean=0.010, rw_bound=0.000, batch=1\n",
      "1: loss=1.311, reward_mean=0.010, rw_bound=0.000, batch=1\n",
      "2: loss=1.285, reward_mean=0.040, rw_bound=0.000, batch=4\n",
      "3: loss=1.259, reward_mean=0.106, rw_bound=0.000, batch=11\n",
      "4: loss=1.226, reward_mean=0.153, rw_bound=0.000, batch=17\n",
      "5: loss=1.172, reward_mean=0.222, rw_bound=0.000, batch=26\n",
      "6: loss=1.099, reward_mean=0.325, rw_bound=0.117, batch=38\n",
      "7: loss=1.020, reward_mean=0.435, rw_bound=0.282, batch=46\n",
      "8: loss=0.921, reward_mean=0.486, rw_bound=0.349, batch=50\n",
      "9: loss=0.802, reward_mean=0.547, rw_bound=0.430, batch=52\n",
      "10: loss=0.690, reward_mean=0.599, rw_bound=0.478, batch=52\n",
      "11: loss=0.630, reward_mean=0.586, rw_bound=0.478, batch=67\n",
      "12: loss=0.505, reward_mean=0.707, rw_bound=0.531, batch=51\n",
      "13: loss=0.428, reward_mean=0.709, rw_bound=0.531, batch=69\n",
      "14: loss=0.374, reward_mean=0.769, rw_bound=0.531, batch=100\n",
      "15: loss=0.318, reward_mean=0.795, rw_bound=0.531, batch=137\n",
      "16: loss=0.275, reward_mean=0.840, rw_bound=0.531, batch=181\n",
      "Solved!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▁▁▁▁▂▂▂▃▃▃▃▄▃▄▅▆█</td></tr><tr><td>ep_idx</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>loss</td><td>██▇▇▇▇▆▆▅▄▄▃▂▂▂▁▁</td></tr><tr><td>reward_bound</td><td>▁▁▁▁▁▁▃▅▆▇▇▇█████</td></tr><tr><td>reward_mean</td><td>▁▁▁▂▂▃▄▅▅▆▆▆▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>181</td></tr><tr><td>ep_idx</td><td>16</td></tr><tr><td>loss</td><td>0.27474</td></tr><tr><td>reward_bound</td><td>0.53144</td></tr><tr><td>reward_mean</td><td>0.83966</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gallant-capybara-1</strong> at: <a href='https://wandb.ai/achronus-uk/CrossEntropyFrozenLake/runs/8xq12tcz' target=\"_blank\">https://wandb.ai/achronus-uk/CrossEntropyFrozenLake/runs/8xq12tcz</a><br/> View project at: <a href='https://wandb.ai/achronus-uk/CrossEntropyFrozenLake' target=\"_blank\">https://wandb.ai/achronus-uk/CrossEntropyFrozenLake</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241110_100627-8xq12tcz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train2(env: gym.Env, net: nn.Module) -> None:\n",
    "    solve_threshold = 0.8\n",
    "    \n",
    "    wb = WeightsAndBiases(\n",
    "        project_name=\"CrossEntropyFrozenLake\", \n",
    "        config={\n",
    "            \"env\": \"FrozenLake-v1\",\n",
    "            \"slippery\": False,\n",
    "            \"hidden_size\": HIDDEN_SIZE,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"percentile\": PERCENTILE,\n",
    "            \"gamma\": GAMMA,\n",
    "            \"solve_threshold\": solve_threshold,\n",
    "            \"architecture\": net\n",
    "        }\n",
    "    )\n",
    "    wb.init()\n",
    "    full_batch = Episodes()\n",
    "\n",
    "    for i_batch, batch in enumerate(iterate_batches(env, net, BATCH_SIZE)):\n",
    "        full_batch, obs, acts, reward_bound, reward_mean = filter_batch2(batch + full_batch, PERCENTILE)\n",
    "\n",
    "        if not full_batch:\n",
    "            continue\n",
    "\n",
    "        full_batch = full_batch[-500:]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        action_scores_v = net(obs)\n",
    "        loss_v: torch.Tensor = loss(action_scores_v, acts)\n",
    "        loss_v.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"{i_batch}: loss={loss_v.item():.3f}, reward_mean={reward_mean:.3f}, rw_bound={reward_bound:.3f}, batch={len(full_batch)}\")\n",
    "        wb.log({\n",
    "            \"ep_idx\": i_batch,\n",
    "            \"loss\": loss_v,\n",
    "            \"reward_mean\": reward_mean,\n",
    "            \"reward_bound\": reward_bound,\n",
    "            \"batch\": len(full_batch),\n",
    "        })\n",
    "\n",
    "        if reward_mean > solve_threshold:\n",
    "            print(\"Solved!\")\n",
    "            wb.finish()\n",
    "            break\n",
    "\n",
    "train2(env2, net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
